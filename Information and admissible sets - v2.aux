\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{book.manski}
\select@language{UKenglish}
\@writefile{toc}{\select@language{UKenglish}}
\@writefile{lof}{\select@language{UKenglish}}
\@writefile{lot}{\select@language{UKenglish}}
\citation{hEvY05}
\citation{kHt10}
\citation{13.misc.abrevaya}
\citation{crs13}
\citation{bEmOImOF12}
\citation{book.molchanov}
\citation{cr13}
\citation{cr13}
\citation{cHlr13}
\citation{cr13}
\citation{bp97}
\citation{sHvY11}
\citation{c05}
\citation{kI09}
\citation{c10}
\citation{bp97}
\citation{sTw60}
\citation{sHvY11}
\citation{c05}
\citation{kI09}
\citation{c05}
\citation{kI09}
\citation{bp97}
\citation{c10}
\citation{c10}
\citation{h50}
\citation{krE50}
\citation{Angristdatabank}
\citation{ae98}
\citation{ae98}
\citation{cr13}
\@writefile{toc}{\contentsline {section}{\numberline {1}A non-parametric model of binary choice}{4}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Credibility in economic modelling}{5}{section.2}}
\citation{book.manski}
\citation{krE50}
\citation{book.manski}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}The credibility of the single equation model}{6}{subsection.2.1}}
\citation{ai94}
\citation{cr13}
\@writefile{toc}{\contentsline {section}{\numberline {3}Incorporating information}{8}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Enriching the support of the instrumental variable}{8}{subsection.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Enriching individual response}{8}{subsection.3.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:model}{{1a}{9}{A model $\mathcal {M}$ is a set of structures that forms a proper subset of the class of all structures $\mathcal {S}$. Each structure in $\mathcal {M}$ generates a probability distribution in the class of all probability distributions (of observable variables) $\mathcal {P}$. Then the image $\mathcal {I}$ is the set of all probability distributions that are generated by structures in $\mathcal {M}$.\relax }{figure.caption.4}{}}
\newlabel{sub@fig:model}{{a}{9}{A model $\mathcal {M}$ is a set of structures that forms a proper subset of the class of all structures $\mathcal {S}$. Each structure in $\mathcal {M}$ generates a probability distribution in the class of all probability distributions (of observable variables) $\mathcal {P}$. Then the image $\mathcal {I}$ is the set of all probability distributions that are generated by structures in $\mathcal {M}$.\relax }{figure.caption.4}{}}
\newlabel{fig:obs.restrict}{{1b}{9}{A structure $S$ is incompatible with data if it generates a probability distribution (of observable variables) $P$ that is distinct from a realised probability distribution $\mathbb {P}$. If all structures in $\mathcal {M}$ are incompatible with data then $\mathcal {M}$ is said to be observationally restrictive, and is falsified. This condition is equivalent to $\mathbb {P}\in \mathcal {P}\setminus \mathcal {I}$.\relax }{figure.caption.4}{}}
\newlabel{sub@fig:obs.restrict}{{b}{9}{A structure $S$ is incompatible with data if it generates a probability distribution (of observable variables) $P$ that is distinct from a realised probability distribution $\mathbb {P}$. If all structures in $\mathcal {M}$ are incompatible with data then $\mathcal {M}$ is said to be observationally restrictive, and is falsified. This condition is equivalent to $\mathbb {P}\in \mathcal {P}\setminus \mathcal {I}$.\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Structures, models, probability distributions (of observable variables), and falsifiability.\relax }}{9}{figure.caption.4}}
\newlabel{fig:models}{{1}{9}{Structures, models, probability distributions (of observable variables), and falsifiability.\relax }{figure.caption.4}{}}
\newlabel{fig:identify}{{2a}{10}{A model $\mathcal {M}$ is said to identify a structure $S$ if the probability distribution (of observable variables) $P$ that is generated by $S$ is distinct from those generated by other structures in $\mathcal {M}$. The structures $S_a$, $S_b$ and $S_c$ are said to be observationally equivalent as they all generate $P$ but $S_b$ and $S_c$ are not admitted by $\mathcal {M}$. As $S_a$ is the only structure that is admitted by $\mathcal {M}$ and that generates $P$, $S_a$ is identified by $\mathcal {M}$. For completeness, $\mathcal {M}$ is said to be uniformly identifying if it identifies each structure that it admits.\relax }{figure.caption.5}{}}
\newlabel{sub@fig:identify}{{a}{10}{A model $\mathcal {M}$ is said to identify a structure $S$ if the probability distribution (of observable variables) $P$ that is generated by $S$ is distinct from those generated by other structures in $\mathcal {M}$. The structures $S_a$, $S_b$ and $S_c$ are said to be observationally equivalent as they all generate $P$ but $S_b$ and $S_c$ are not admitted by $\mathcal {M}$. As $S_a$ is the only structure that is admitted by $\mathcal {M}$ and that generates $P$, $S_a$ is identified by $\mathcal {M}$. For completeness, $\mathcal {M}$ is said to be uniformly identifying if it identifies each structure that it admits.\relax }{figure.caption.5}{}}
\newlabel{fig:partial}{{2b}{10}{As $S_a$ and $S_b$ are observationally equivalent and are both admitted by $\mathcal {M}$ then $\mathcal {M}$ does not identify either $S_a$ or $S_b$. Nonetheless, as $\mathcal {M}$ restricts the set of observationally equivalent structures that generate $P$ to $S_a$ and $S_b$ then $\mathcal {M}$ partially identifies $S_a$ (and $S_b$ to within $\lbrace S_a,S_b\rbrace $).\relax }{figure.caption.5}{}}
\newlabel{sub@fig:partial}{{b}{10}{As $S_a$ and $S_b$ are observationally equivalent and are both admitted by $\mathcal {M}$ then $\mathcal {M}$ does not identify either $S_a$ or $S_b$. Nonetheless, as $\mathcal {M}$ restricts the set of observationally equivalent structures that generate $P$ to $S_a$ and $S_b$ then $\mathcal {M}$ partially identifies $S_a$ (and $S_b$ to within $\lbrace S_a,S_b\rbrace $).\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Identification and non-identification of a structure, and partial identification of a structure.\relax }}{10}{figure.caption.5}}
\newlabel{fig:identification}{{2}{10}{Identification and non-identification of a structure, and partial identification of a structure.\relax }{figure.caption.5}{}}
\newlabel{fig:characteristic}{{3a}{11}{A structural characteristic $\chi $ is a function of a structure $S$. A model $\mathcal {M}$ can be partitioned such that structures in a partition deliver the same value for $\chi $. Structures in the red partition $\color {red}\mathcal {M}$ deliver the value $a$ for $\chi $, and structures in the red partition $\color {blue}\mathcal {M}$ deliver the value $b$ for $\chi $. If $\chi $ is constant across all observationally equivalent structures that $\mathcal {M}$ admits then $\mathcal {M}$ is said to identify $\chi $. As $\chi (S_a)$ is equal to $\chi (S_b)$ (is equal to $a$) $\mathcal {M}$ identifies $\chi $.\relax }{figure.caption.6}{}}
\newlabel{sub@fig:characteristic}{{a}{11}{A structural characteristic $\chi $ is a function of a structure $S$. A model $\mathcal {M}$ can be partitioned such that structures in a partition deliver the same value for $\chi $. Structures in the red partition $\color {red}\mathcal {M}$ deliver the value $a$ for $\chi $, and structures in the red partition $\color {blue}\mathcal {M}$ deliver the value $b$ for $\chi $. If $\chi $ is constant across all observationally equivalent structures that $\mathcal {M}$ admits then $\mathcal {M}$ is said to identify $\chi $. As $\chi (S_a)$ is equal to $\chi (S_b)$ (is equal to $a$) $\mathcal {M}$ identifies $\chi $.\relax }{figure.caption.6}{}}
\newlabel{fig:uniform}{{3b}{11}{If $\mathcal {M}$ identifies $\chi $ for all structures in $\mathcal {M}$ then $\mathcal {M}$ is said to uniformly identify $\chi $. The class of all probability distributions (of observable variables) is partitioned into the blue partition $\color {red}\mathcal {P}$ and into the red partition $\color {blue}\mathcal {P}$. Probability distributions in $\color {red}\mathcal {P}$ are generated by (potentially many) structures in $\color {red}\mathcal {M}$, and probability distributions in $\color {blue}\mathcal {P}$ are generated by (potentially many) structures in $\color {blue}\mathcal {M}$. It is important that the number of partitions in $\mathcal {M}$ and in $\mathcal {P}$ are equal, although that number can be countably infinite. In the context of Figure~\ref {fig:uniform} $\mathcal {M}$ uniformly identifies $\chi $ since observationally equivalent structures that $\mathcal {M}$ admits are in the same colour of $\mathcal {M}$. More conveniently, whether $\mathcal {M}$ uniformly identifies $\chi $ can be determined by the existence of an identifying correspondence $G$, a functional. $\color {red}P$ is a probability distribution in $\color {red}\mathcal {P}$, and $\color {blue}P$ is a probability distribution in $\color {blue}\mathcal {P}$. Then $\mathcal {M}$ uniformly identifies $\chi $ if the value of $G(\color {red}P\color {black})$ is $a$ and if the value of $G(\color {blue}P\color {black})$ is $b$, holding for any such $\color {red}P$ and $\color {blue}P$. Notice that if $\mathcal {M}$ uniformly identifies all $\chi $ then $\mathcal {M}$ also uniformly identifies structures.\relax }{figure.caption.6}{}}
\newlabel{sub@fig:uniform}{{b}{11}{If $\mathcal {M}$ identifies $\chi $ for all structures in $\mathcal {M}$ then $\mathcal {M}$ is said to uniformly identify $\chi $. The class of all probability distributions (of observable variables) is partitioned into the blue partition $\color {red}\mathcal {P}$ and into the red partition $\color {blue}\mathcal {P}$. Probability distributions in $\color {red}\mathcal {P}$ are generated by (potentially many) structures in $\color {red}\mathcal {M}$, and probability distributions in $\color {blue}\mathcal {P}$ are generated by (potentially many) structures in $\color {blue}\mathcal {M}$. It is important that the number of partitions in $\mathcal {M}$ and in $\mathcal {P}$ are equal, although that number can be countably infinite. In the context of Figure~\ref {fig:uniform} $\mathcal {M}$ uniformly identifies $\chi $ since observationally equivalent structures that $\mathcal {M}$ admits are in the same colour of $\mathcal {M}$. More conveniently, whether $\mathcal {M}$ uniformly identifies $\chi $ can be determined by the existence of an identifying correspondence $G$, a functional. $\color {red}P$ is a probability distribution in $\color {red}\mathcal {P}$, and $\color {blue}P$ is a probability distribution in $\color {blue}\mathcal {P}$. Then $\mathcal {M}$ uniformly identifies $\chi $ if the value of $G(\color {red}P\color {black})$ is $a$ and if the value of $G(\color {blue}P\color {black})$ is $b$, holding for any such $\color {red}P$ and $\color {blue}P$. Notice that if $\mathcal {M}$ uniformly identifies all $\chi $ then $\mathcal {M}$ also uniformly identifies structures.\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The identification of structural characteristics, and identifying correspondences.\relax }}{11}{figure.caption.6}}
\newlabel{fig:characteristics}{{3}{11}{The identification of structural characteristics, and identifying correspondences.\relax }{figure.caption.6}{}}
\newlabel{fig:partial1}{{4b}{12}{That probability distributions in $\color {gray}\mathcal {P}$ are generated by structures in $\color {red}\mathcal {M}$ and in $\color {yellow}\mathcal {M}$ creates a complication; the value of $\chi $ is not constant across observationally equivalent structures that $\mathcal {M}$ admits and that generate a probability distribution in $\color {gray}\mathcal {P}$. So $\mathcal {M}$ does not uniformly identify $\chi $. Consideration of the identifying correspondence $G$ determines that this corresponds to there being structures in $\mathcal {M}$ for which $G$ does not deliver the value of $\chi $ when applied to the probability distributions that these structures generate. Nonetheless, if $\mathcal {M}$ restricts the set of values of $\chi $ for any probability distribution in $\mathcal {P}$ then $\mathcal {M}$ does have some non-trivial identifying power for $\chi $. Then $\mathcal {M}$ is said to uniformly partially identify $\chi $ if $\mathcal {M}$ and $\mathcal {P}$ can each be partitioned into countably many disjoint subsets and that a probability distribution in a partition of $\mathcal {P}$ is not generated by a structure in at least one partition of $\mathcal {M}$, holding for any such partition of $\mathcal {P}$. In the context of Figure~\ref {fig:partials} $\color {red}\mathcal {M}$ identifies $\chi $ up to $\lbrace a,c\rbrace $, $\color {blue}\mathcal {M}$ identifies $\chi $ uniquely to $b$, and $\color {yellow}\mathcal {M}$ identifies $\chi $ up to $\lbrace a,c\rbrace $. Each partition of $\mathcal {P}$ includes probability distributions that are generated by structures in at least one partition of $\mathcal {M}$. Equivalently, if $G$ is permitted to be a multivalued functional (or one-to-many) then $\mathcal {M}$ uniformly partially identifies $\chi $ if $G$ exists and if $G(P)$ contains the set of values of $\chi $ that are delivered by structures that generate $P$, holding for all such $P$. A caveat must be applied here; $G$ cannot be trivial in the sense that it is constant across all such $P$. Clearly this definition of $G$ does not exclude the possibility that there is multiplicity of identifying correspondences that satisfy this property. Sharpness is a desirable property in such circumstances; a functional $G$ that can be shown to deliver smaller sets according to some well-defined distance measure across all possible $P$ (and that satisfies the properties above) should be preferred to any alternative identifying correspondence.\relax }{figure.caption.7}{}}
\newlabel{sub@fig:partial1}{{b}{12}{That probability distributions in $\color {gray}\mathcal {P}$ are generated by structures in $\color {red}\mathcal {M}$ and in $\color {yellow}\mathcal {M}$ creates a complication; the value of $\chi $ is not constant across observationally equivalent structures that $\mathcal {M}$ admits and that generate a probability distribution in $\color {gray}\mathcal {P}$. So $\mathcal {M}$ does not uniformly identify $\chi $. Consideration of the identifying correspondence $G$ determines that this corresponds to there being structures in $\mathcal {M}$ for which $G$ does not deliver the value of $\chi $ when applied to the probability distributions that these structures generate. Nonetheless, if $\mathcal {M}$ restricts the set of values of $\chi $ for any probability distribution in $\mathcal {P}$ then $\mathcal {M}$ does have some non-trivial identifying power for $\chi $. Then $\mathcal {M}$ is said to uniformly partially identify $\chi $ if $\mathcal {M}$ and $\mathcal {P}$ can each be partitioned into countably many disjoint subsets and that a probability distribution in a partition of $\mathcal {P}$ is not generated by a structure in at least one partition of $\mathcal {M}$, holding for any such partition of $\mathcal {P}$. In the context of Figure~\ref {fig:partials} $\color {red}\mathcal {M}$ identifies $\chi $ up to $\lbrace a,c\rbrace $, $\color {blue}\mathcal {M}$ identifies $\chi $ uniquely to $b$, and $\color {yellow}\mathcal {M}$ identifies $\chi $ up to $\lbrace a,c\rbrace $. Each partition of $\mathcal {P}$ includes probability distributions that are generated by structures in at least one partition of $\mathcal {M}$. Equivalently, if $G$ is permitted to be a multivalued functional (or one-to-many) then $\mathcal {M}$ uniformly partially identifies $\chi $ if $G$ exists and if $G(P)$ contains the set of values of $\chi $ that are delivered by structures that generate $P$, holding for all such $P$. A caveat must be applied here; $G$ cannot be trivial in the sense that it is constant across all such $P$. Clearly this definition of $G$ does not exclude the possibility that there is multiplicity of identifying correspondences that satisfy this property. Sharpness is a desirable property in such circumstances; a functional $G$ that can be shown to deliver smaller sets according to some well-defined distance measure across all possible $P$ (and that satisfies the properties above) should be preferred to any alternative identifying correspondence.\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Partial identification of a structural characteristic.\relax }}{12}{figure.caption.7}}
\newlabel{fig:partials}{{4}{12}{Partial identification of a structural characteristic.\relax }{figure.caption.7}{}}
\newlabel{fig:indistinguishable1}{{\caption@xref {fig:indistinguishable1}{ on input line 448}}{13}{Enriching individual response}{figure.caption.8}{}}
\newlabel{sub@fig:indistinguishable1}{{}{13}{Enriching individual response}{figure.caption.8}{}}
\newlabel{fig:indistinguishable2}{{\caption@xref {fig:indistinguishable2}{ on input line 453}}{13}{Enriching individual response}{figure.caption.8}{}}
\newlabel{sub@fig:indistinguishable2}{{}{13}{Enriching individual response}{figure.caption.8}{}}
\newlabel{fig:exogenous1}{{\caption@xref {fig:exogenous1}{ on input line 461}}{13}{Enriching individual response}{figure.caption.8}{}}
\newlabel{sub@fig:exogenous1}{{a}{13}{Enriching individual response}{figure.caption.8}{}}
\newlabel{fig:exogenous2}{{\caption@xref {fig:exogenous2}{ on input line 466}}{13}{Enriching individual response}{figure.caption.8}{}}
\newlabel{sub@fig:exogenous2}{{a}{13}{Enriching individual response}{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces A note on causality.\relax }}{13}{figure.caption.8}}
\newlabel{fig:causality}{{5}{13}{A note on causality.\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces $ACE(D\rightarrow Y)$ is recoverable from the plot of the admissible set of values of $(\mathbb  {E}[Y(1)],\mathbb  {E}[Y(0)])$. First, note that $ACE(D\rightarrow Y)$ is increasing in the $y$-direction and is decreasing in the $x$-direction. Any line with unit gradient then represents all points along which $ACE(D\rightarrow Y)$ is constant. Projecting the admissible set of values of $(\mathbb  {E}[Y(1)],\mathbb  {E}[Y(0)])$ from the normal of the $45^\circ $ line onto the $y$-axis yields the admissible set of values of $ACE(D\rightarrow Y)$. The blue rectangle is the admissible set of values of $(\mathbb  {E}[Y(1)],\mathbb  {E}[Y(0)])$, and the union of the blue rectangle and the red polygon is the $(1-\alpha )$-confidence region of $(\mathbb  {E}[Y(1)],\mathbb  {E}[Y(0)])$. \relax }}{14}{figure.caption.9}}
\newlabel{fig:ace}{{6}{14}{$ACE(D\rightarrow Y)$ is recoverable from the plot of the admissible set of values of $(\mathbb {E}[Y(1)],\mathbb {E}[Y(0)])$. First, note that $ACE(D\rightarrow Y)$ is increasing in the $y$-direction and is decreasing in the $x$-direction. Any line with unit gradient then represents all points along which $ACE(D\rightarrow Y)$ is constant. Projecting the admissible set of values of $(\mathbb {E}[Y(1)],\mathbb {E}[Y(0)])$ from the normal of the $45^\circ $ line onto the $y$-axis yields the admissible set of values of $ACE(D\rightarrow Y)$. The blue rectangle is the admissible set of values of $(\mathbb {E}[Y(1)],\mathbb {E}[Y(0)])$, and the union of the blue rectangle and the red polygon is the $(1-\alpha )$-confidence region of $(\mathbb {E}[Y(1)],\mathbb {E}[Y(0)])$. \relax }{figure.caption.9}{}}
\bibstyle{chicago}
\bibdata{C:/Dropbox/TeXTemplates/Bibliography}
\bibcite{13.misc.abrevaya}{{1}{2013}{{Abrevaya et~al.}}{{Abrevaya, Hsu, and Lieli}}}
\bibcite{Angristdatabank}{{2}{2014}{{Angrist}}{{Angrist}}}
\bibcite{ae98}{{3}{1998}{{Angrist and Evans}}{{Angrist and Evans}}}
\bibcite{bp97}{{4}{1997}{{Balke and Pearl}}{{Balke and Pearl}}}
\bibcite{bEmOImOF12}{{5}{2012}{{Beresteanu et~al.}}{{Beresteanu, Molchanov, and Molinari}}}
\bibcite{cHlr13}{{6}{2013}{{Chernozhukov et~al.}}{{Chernozhukov, Lee, and Rosen}}}
\bibcite{c05}{{7}{2005}{{Chesher}}{{Chesher}}}
\bibcite{c10}{{8}{2010}{{Chesher}}{{Chesher}}}
\bibcite{cr13}{{9}{2013}{{Chesher and Rosen}}{{Chesher and Rosen}}}
\bibcite{crs13}{{10}{2013}{{Chesher et~al.}}{{Chesher, Rosen, and Smolinski}}}
\bibcite{hE78}{{11}{1978}{{Heckman}}{{Heckman}}}
\bibcite{hEvY05}{{12}{2005}{{Heckman and Vytlacil}}{{Heckman and Vytlacil}}}
\bibcite{h50}{{13}{1950}{{Hurwicz}}{{Hurwicz}}}
\bibcite{ai94}{{14}{1994}{{Imbens and Angrist}}{{Imbens and Angrist}}}
\bibcite{kHt10}{{15}{2010}{{Khan and Tamer}}{{Khan and Tamer}}}
\bibcite{kI09}{{16}{2009}{{Kitagawa}}{{Kitagawa}}}
\bibcite{krE50}{{17}{1950}{{Koopmans and Reiers{\o }l}}{{Koopmans and Reiers{\o }l}}}
\bibcite{book.manski}{{18}{2013}{{Manski}}{{Manski}}}
\bibcite{book.molchanov}{{19}{2005}{{Molchanov}}{{Molchanov}}}
\bibcite{p93}{{20}{1993}{{Pearl}}{{Pearl}}}
\bibcite{sHvY11}{{21}{2011}{{Shaikh and Vytlacil}}{{Shaikh and Vytlacil}}}
\bibcite{sTw60}{{22}{1960}{{Strotz and Wold}}{{Strotz and Wold}}}
